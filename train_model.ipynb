{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a26f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcc6e47",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0fa79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features\n",
    "df = pd.read_csv('data/f1_tyre_features.csv')\n",
    "print(f\"Loaded {len(df):,} samples\")\n",
    "print(f\"Features: {df.shape[1] - 1}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['Compound'].value_counts())\n",
    "print(f\"\\nData Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23722af",
   "metadata": {},
   "source": [
    "## 2. Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a16dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('Compound', axis=1)\n",
    "y = df['Compound']\n",
    "\n",
    "# Encode target variable\n",
    "le_compound = LabelEncoder()\n",
    "y_encoded = le_compound.fit_transform(y)\n",
    "\n",
    "print(f\"Feature shape: {X.shape}\")\n",
    "print(f\"Target shape: {y_encoded.shape}\")\n",
    "print(f\"\\nCompound encoding:\")\n",
    "for i, compound in enumerate(le_compound.classes_):\n",
    "    print(f\"  {compound}: {i}\")\n",
    "\n",
    "# Save label encoder\n",
    "joblib.dump(le_compound, 'model/label_encoder.pkl')\n",
    "print(\"\\n‚úì Label encoder saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
    "print(f\"\\nTraining set distribution:\")\n",
    "print(pd.Series(y_train).value_counts().sort_index())\n",
    "print(f\"\\nTest set distribution:\")\n",
    "print(pd.Series(y_test).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fba27fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, 'model/scaler.pkl')\n",
    "print(\"‚úì Feature scaler saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2dd0d",
   "metadata": {},
   "source": [
    "## 3. Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e5e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=200, \n",
    "        max_depth=20, \n",
    "        min_samples_split=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        eval_metric='mlogloss'\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le_compound.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f1c71",
   "metadata": {},
   "source": [
    "## 4. Select Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46789d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Test Accuracy': [r['accuracy'] for r in results.values()],\n",
    "    'CV Mean': [r['cv_mean'] for r in results.values()],\n",
    "    'CV Std': [r['cv_std'] for r in results.values()]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Select best model (highest test accuracy)\n",
    "best_model_name = max(results, key=lambda x: results[x]['accuracy'])\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   Accuracy: {results[best_model_name]['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec6337f",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25308ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from best model\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(feature_importance.head(10).to_string(index=False))\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance.head(15)\n",
    "    plt.barh(range(len(top_features)), top_features['Importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top 15 Feature Importances - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úì Feature importance plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caea27a",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b5632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for best model\n",
    "cm = confusion_matrix(y_test, results[best_model_name]['predictions'])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=le_compound.classes_,\n",
    "            yticklabels=le_compound.classes_)\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.ylabel('True Compound')\n",
    "plt.xlabel('Predicted Compound')\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Confusion matrix saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5117cb",
   "metadata": {},
   "source": [
    "## 7. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce7112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "joblib.dump(best_model, 'model/tyre_recommender.pkl')\n",
    "joblib.dump(X.columns.tolist(), 'model/feature_columns.pkl')\n",
    "\n",
    "print(\"‚úì Model saved to model/tyre_recommender.pkl\")\n",
    "print(\"‚úì Feature columns saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec37b16",
   "metadata": {},
   "source": [
    "## 8. Test Model with Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9831e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample scenarios for testing\n",
    "sample_scenarios = [\n",
    "    {\n",
    "        'name': 'Hot Weather, Early Race',\n",
    "        'features': {\n",
    "            'AirTemp': 35, 'TrackTemp': 45, 'Humidity': 40, 'Rainfall_Binary': 0,\n",
    "            'TrackType_Encoded': 0, 'TyreSeverity_Encoded': 2, 'TotalCorners': 16, 'TrackLength': 5.0,\n",
    "            'LapNumber': 5, 'RaceProgress': 0.1, 'Stint': 1, 'TyreLife': 5, 'StintPhase_Encoded': 0,\n",
    "            'TyreManagementScore': 0.8, 'TyreDegradation': 0.02, 'TempCompoundScore': 5\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'Cool Weather, Mid Race',\n",
    "        'features': {\n",
    "            'AirTemp': 18, 'TrackTemp': 25, 'Humidity': 60, 'Rainfall_Binary': 0,\n",
    "            'TrackType_Encoded': 0, 'TyreSeverity_Encoded': 1, 'TotalCorners': 18, 'TrackLength': 5.5,\n",
    "            'LapNumber': 30, 'RaceProgress': 0.5, 'Stint': 2, 'TyreLife': 15, 'StintPhase_Encoded': 1,\n",
    "            'TyreManagementScore': 0.85, 'TyreDegradation': 0.05, 'TempCompoundScore': -5\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'Rainy Conditions',\n",
    "        'features': {\n",
    "            'AirTemp': 15, 'TrackTemp': 18, 'Humidity': 95, 'Rainfall_Binary': 1,\n",
    "            'TrackType_Encoded': 1, 'TyreSeverity_Encoded': 0, 'TotalCorners': 20, 'TrackLength': 4.5,\n",
    "            'LapNumber': 20, 'RaceProgress': 0.35, 'Stint': 2, 'TyreLife': 8, 'StintPhase_Encoded': 1,\n",
    "            'TyreManagementScore': 0.75, 'TyreDegradation': 0.01, 'TempCompoundScore': 0\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for scenario in sample_scenarios:\n",
    "    # Create feature vector\n",
    "    features = pd.DataFrame([scenario['features']])[X.columns]\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    # Predict\n",
    "    prediction = best_model.predict(features_scaled)\n",
    "    probabilities = best_model.predict_proba(features_scaled)[0]\n",
    "    \n",
    "    predicted_compound = le_compound.inverse_transform(prediction)[0]\n",
    "    \n",
    "    print(f\"\\n{scenario['name']}:\")\n",
    "    print(f\"  Recommended: {predicted_compound}\")\n",
    "    print(f\"  Confidence:\")\n",
    "    for i, compound in enumerate(le_compound.classes_):\n",
    "        print(f\"    {compound}: {probabilities[i]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e09761",
   "metadata": {},
   "source": [
    "## 9. Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10adbb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Test Accuracy: {results[best_model_name]['accuracy']:.4f}\")\n",
    "print(f\"CV Accuracy: {results[best_model_name]['cv_mean']:.4f} (+/- {results[best_model_name]['cv_std']:.4f})\")\n",
    "print(f\"\\nTraining Samples: {len(X_train):,}\")\n",
    "print(f\"Test Samples: {len(X_test):,}\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Classes: {len(le_compound.classes_)}\")\n",
    "print(f\"\\nSaved Files:\")\n",
    "print(\"  - model/tyre_recommender.pkl\")\n",
    "print(\"  - model/scaler.pkl\")\n",
    "print(\"  - model/label_encoder.pkl\")\n",
    "print(\"  - model/feature_columns.pkl\")\n",
    "print(\"\\n‚úì Model is ready for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
